[solana-sdk.clock]

[solana-core]
CRDS_GOSSIP_NUM_ACTIVE = 30 # usize
CRDS_GOSSIP_PUSH_FANOUT = 6 # usize
# With a fanout of 6, a 1000 node cluster should only take ~4 hops to converge.
# However since pushes are stake weighed, some trailing nodes
# might need more time to receive values. 30 seconds should be plenty.
CRDS_GOSSIP_PUSH_MSG_TIMEOUT_MS = 30000 # u64
CRDS_GOSSIP_PRUNE_MSG_TIMEOUT_MS = 500 # u64
CRDS_GOSSIP_PRUNE_STAKE_THRESHOLD_PCT = 0.15 # f64
CRDS_GOSSIP_PRUNE_MIN_INGRESS_NODES = 3 # usize
# Do not push to peers which have not been updated for this long.
PUSH_ACTIVE_TIMEOUT_MS  = 60_000 # u64
# 10 minutes
MAX_PUSHED_TO_TIMEOUT_MS = 60000 # u64 = 10 * 60 * 1000


RECV_BATCH_MAX_CPU = 1_000 # usize
RECV_BATCH_MAX_GPU = 5_000 # usize


# Transaction forwarding
FORWARD_TRANSACTIONS_TO_LEADER_AT_SLOT_OFFSET = 1 # u64
# Fixed thread size seems to be fastest on GCP setup
NUM_THREADS = 4 # u32
TOTAL_BUFFERED_PACKETS = 500_000 # usize
MAX_NUM_TRANSACTIONS_PER_BATCH = 128 # usize

# Delay uploading the largest confirmed root for this many slots.
LARGEST_CONFIRMED_ROOT_UPLOAD_DELAY = 100 # usize


[solana-perf]
NUM_PACKETS = 8192 # usize = 1024 * 8
PACKETS_PER_BATCH = 256 # usize
NUM_RCVMMSGS = 128 # usize


[solana-runtime]
INTERVAL_MS = 100 # u64
SHRUNKEN_ACCOUNT_PER_SEC = 250 # usize
CLEAN_INTERVAL_BLOCKS = 100 # u64

PAGE_SIZE = 4096 # u64
DEFAULT_NUM_THREADS = 8 # u32
DEFAULT_NUM_DIRS = 4 # u32

ITER_BATCH_SIZE = 1000 # u32

MAX_LEADER_SCHEDULE_STAKES = 5 # Epoch

VOTE_THRESHOLD_SIZE = 0.6666667 # f64

# The default stake placed with the bootstrap validator
BOOTSTRAP_VALIDATOR_LAMPORTS = 42 # u64

MAX_STREAM_SIZE = 3422552064 # = 32 * 1024 * 1024 * 1024 # u64

NUM_BLOCKHASH_CONFIRMATIONS = 3 # usize



[solana-ramp-tps]
#  The percentage of leader slots that validators complete in order to receive the stake reward at the end of a TPS round.
MIN_LEADER_SLOT_PCT = 80.0

[solana-ledger]
# Attempt to upload this many blocks in parallel
NUM_BLOCKS_TO_UPLOAD_IN_PARALLEL = 32 # usize
MAX_COMPLETED_SLOTS_IN_CHANNEL = 100_000 # usize
MAX_TURBINE_PROPAGATION_IN_MS = 100 # u64

# An upper bound on maximum number of data shreds we can handle in a slot
# 32K shreds would allow ~320K peak TPS
# (32K shreds per slot * 4 TX per shred * 2.5 slots per sec)
MAX_DATA_SHREDS_PER_SLOT = 32_768 # usize

SIGN_SHRED_GPU_MIN = 256 # usize
MAX_SCHEDULES = 10 # usize