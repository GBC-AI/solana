[solana-core]
CRDS_GOSSIP_NUM_ACTIVE = 30 # usize
CRDS_GOSSIP_PUSH_FANOUT = 6 # usize
# With a fanout of 6, a 1000 node cluster should only take ~4 hops to converge.
# However since pushes are stake weighed, some trailing nodes
# might need more time to receive values. 30 seconds should be plenty.
CRDS_GOSSIP_PUSH_MSG_TIMEOUT_MS = 30000 # u64
CRDS_GOSSIP_PRUNE_MSG_TIMEOUT_MS = 500 # u64
CRDS_GOSSIP_PRUNE_STAKE_THRESHOLD_PCT = 0.15 # f64
CRDS_GOSSIP_PRUNE_MIN_INGRESS_NODES = 3 # usize
# Do not push to peers which have not been updated for this long.
PUSH_ACTIVE_TIMEOUT_MS  = 60_000 # u64
# 10 minutes
MAX_PUSHED_TO_TIMEOUT_MS = 60000 # u64 = 10 * 60 * 1000


RECV_BATCH_MAX_CPU = 1_000 # usize
RECV_BATCH_MAX_GPU = 5_000 # usize


# Transaction forwarding
FORWARD_TRANSACTIONS_TO_LEADER_AT_SLOT_OFFSET = 1 # u64
# Fixed thread size seems to be fastest on GCP setup
NUM_THREADS = 4 # u32
TOTAL_BUFFERED_PACKETS = 500_000 # usize
MAX_NUM_TRANSACTIONS_PER_BATCH = 128 # usize

# Delay uploading the largest confirmed root for this many slots.
LARGEST_CONFIRMED_ROOT_UPLOAD_DELAY = 100 # usize

NUM_INSERT_THREADS = 2 # usize
# This parameter tunes how many entries are received in one iteration of recv loop
# This will prevent broadcast stage from consuming more entries, that could have led
# to delays in shredding, and broadcasting shreds to peer validators
RECEIVE_ENTRY_COUNT_THRESHOLD = 8 # usize

NUM_BAD_SLOTS = 10 # u64
SLOT_TO_RESOLVE = 32 # u32

BROADCAST_PEER_UPDATE_INTERVAL_MS = 1000 # u64

# The Data plane fanout size, also used as the neighborhood size
DATA_PLANE_FANOUT = 200 # usize
# milliseconds we sleep for between gossip requests
GOSSIP_SLEEP_MILLIS = 100 # u64
# The maximum size of a bloom filter
MAX_CRDS_OBJECT_SIZE  = 928 # usize
# The largest protocol header size
MAX_PROTOCOL_HEADER_SIZE = 214 # u64

# Keep the number of snapshot hashes a node publishes under MAX_PROTOCOL_PAYLOAD_SIZE
MAX_SNAPSHOT_HASHES = 16 # usize
# Number of bytes in the randomly generated token sent with ping messages.
GOSSIP_PING_CACHE_CAPACITY = 16384 # usize
GOSSIP_PING_CACHE_TTL = 640 # u64: seconds

VOTE_THRESHOLD_DEPTH = 8 # usize
SWITCH_FORK_THRESHOLD = 0.38 # f64

# The min size for bloom filters
CRDS_GOSSIP_DEFAULT_BLOOM_ITEMS = 500 # usize

CRDS_GOSSIP_PULL_CRDS_TIMEOUT_MS = 15000 # u64
# The maximum age of a value received over pull responses
CRDS_GOSSIP_PULL_MSG_TIMEOUT_MS = 60000 # u64
# Retention period of hashes of received outdated values.
FAILED_INSERTS_RETENTION_MS = 20_000 # u64


# - To try and keep the RocksDB size under 400GB:
#   Seeing about 1600b/shred, using 2000b/shred for margin, so 200m shreds can be stored in 400gb.
#   at 5k shreds/slot at 50k tps, this is 500k slots (~5 hours).
#   At idle, 60 shreds/slot this is about 4m slots (18 days)
# This is chosen to allow enough time for
# - A validator to download a snapshot from a peer and boot from it
# - To make sure that if a validator needs to reboot from its own snapshot, it has enough slots locally
#   to catch back up to where it was when it stopped
DEFAULT_MAX_LEDGER_SHREDS = 200_000_000 # u64
# Allow down to 50m, or 3.5 days at idle, 1hr at 50k load, around ~100GB
DEFAULT_MIN_MAX_LEDGER_SHREDS = 50_000_000 # u64
# Check for removing slots at this interval so we don't purge too often
# and starve other blockstore users.
DEFAULT_PURGE_SLOT_INTERVAL = 512 # u64

GRACE_TICKS_FACTOR = 2 # u64
MAX_GRACE_SLOTS = 2 # u64

MAX_ENTRY_RECV_PER_ITER = 512 # usize
SUPERMINORITY_THRESHOLD = 0.3333333 # f64
MAX_UNCONFIRMED_SLOTS = 5 # usize


[solana-perf]
NUM_PACKETS = 8192 # usize = 1024 * 8
PACKETS_PER_BATCH = 256 # usize


[solana-runtime]
INTERVAL_MS = 100 # u64
SHRUNKEN_ACCOUNT_PER_SEC = 250 # usize
CLEAN_INTERVAL_BLOCKS = 100 # u64

PAGE_SIZE = 4096 # u64
DEFAULT_NUM_THREADS = 8 # u32
DEFAULT_NUM_DIRS = 4 # u32

ITER_BATCH_SIZE = 1000 # u32

MAX_LEADER_SCHEDULE_STAKES = 5 # Epoch

VOTE_THRESHOLD_SIZE = 0.6666667 # f64

# The default stake placed with the bootstrap validator
BOOTSTRAP_VALIDATOR_LAMPORTS = 42 # u64

MAX_STREAM_SIZE = 3422552064 # = 32 * 1024 * 1024 * 1024 # u64

NUM_BLOCKHASH_CONFIRMATIONS = 3 # usize



[solana-ramp-tps]
#  The percentage of leader slots that validators complete in order to receive the stake reward at the end of a TPS round.
MIN_LEADER_SLOT_PCT = 80.0

[solana-ledger]
# Attempt to upload this many blocks in parallel
NUM_BLOCKS_TO_UPLOAD_IN_PARALLEL = 32 # usize
MAX_COMPLETED_SLOTS_IN_CHANNEL = 100_000 # usize
MAX_TURBINE_PROPAGATION_IN_MS = 100 # u64

# An upper bound on maximum number of data shreds we can handle in a slot
# 32K shreds would allow ~320K peak TPS
# (32K shreds per slot * 4 TX per shred * 2.5 slots per sec)
MAX_DATA_SHREDS_PER_SLOT = 32_768 # usize

SIGN_SHRED_GPU_MIN = 256 # usize
MAX_SCHEDULES = 10 # usize




[solana-bpf-loader-program]
# Default program heap size, allocators are expected to enforce this
DEFAULT_HEAP_SIZE = 32_768 # usize = 32kb


[solana-program]
# The default tick rate that the cluster attempts to achieve.  Note that the actual tick
# rate at any given time should be expected to drift
DEFAULT_TICKS_PER_SECOND = 160 # 64
# At 160 ticks/s, 64 ticks per slot implies that leader rotation and voting will happen
# every 400 ms. A fast voting cadence ensures faster finality and convergence
DEFAULT_TICKS_PER_SLOT = 64 # u64
# GCP n1-standard hardware and also a xeon e5-2520 v4 are about this rate of hashes/s
DEFAULT_HASHES_PER_SECOND = 2_000_000 # u64
# 1 Dev Epoch = 400 ms * 8192 ~= 55 minutes
DEFAULT_DEV_SLOTS_PER_EPOCH = 8192 # u64

DEFAULT_TARGET_LAMPORTS_PER_SIGNATURE = 10_000 # u64

# leader schedule is governed by this
NUM_CONSECUTIVE_LEADER_SLOTS = 4 # u64
# The time window of recent block hash values that the bank will track the signatures
# of over. Once the bank discards a block hash, it will reject any transactions that use
# that `recent_blockhash` in a transaction. Lowering this value reduces memory consumption,
# but requires clients to update its `recent_blockhash` more frequently. Raising the value
# lengthens the time a client must wait to be certain a missing transaction will
# not be processed by the network.
MAX_HASH_AGE_IN_SECONDS = 120 # usize
# This is maximum time consumed in forwarding a transaction from one node to next, before
# it can be processed in the target node
MAX_TRANSACTION_FORWARDING_DELAY_GPU = 2 # usize
# More delay is expected if CUDA is not enabled (as signature verification takes longer)
MAX_TRANSACTION_FORWARDING_DELAY = 6 # usize

# The maximum number of slots before an epoch starts to calculate the leader schedule.
#  Default is an entire epoch, i.e. leader schedule for epoch X is calculated at
#  the beginning of epoch X - 1.
MAX_LEADER_SCHEDULE_EPOCH_OFFSET = 3 # u64
MINIMUM_SLOTS_PER_EPOCH = 32 # u64

# default rental rate in lamports/byte-year, based on:
#  10^9 lamports per SOL
#  $1 per SOL
#  $0.01 per megabyte day
#  $3.65 per megabyte year
DEFAULT_LAMPORTS_PER_BYTE_YEAR = 3480 # u64 = 1_000_000_000 / 100 * 365 / (1024 * 1024)
# default amount of time (in years) the balance has to include rent for
DEFAULT_EXEMPTION_THRESHOLD = 2.0 # f64
# default percentage of rent to burn (Valid values are 0 to 100)
DEFAULT_BURN_PERCENT = 50 # u8
# account storage overhead for calculation of base rent
ACCOUNT_STORAGE_OVERHEAD = 128 # u64

# about 2.5 minutes to get your vote in
SLOT_MAX_ENTRIES = 512 # usize
# it should never take as many as 512 epochs to warm up or cool down
STAKE_HISTORY_MAX_ENTRIES = 512 # usize
# 1 million slots is about 5 days
SLOT_HISTORY_MAX_ENTRIES = 1048576 # u64 = 1024 * 1024
RECENT_BLOCKHASHES_MAX_ENTRIES = 150 # usize

[solana-sdk]
# Network inflation
DEFAULT_INITIAL = 0.08 # f64
DEFAULT_TERMINAL = 0.015 # f64
DEFAULT_TAPER = 0.15 # f64
DEFAULT_FOUNDATION = 0.05 # f64
DEFAULT_FOUNDATION_TERM = 7.0 # f64

PBKDF2_ROUNDS = 2048 # usize
PBKDF2_BYTES = 64 # usize